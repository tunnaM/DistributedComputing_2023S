{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add609d2",
   "metadata": {},
   "source": [
    "# Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486aee15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    config(\"spark.executor.memory\", \"4g\").\\\n",
    "    config(\"spark.driver.memory\", \"4g\").\\\n",
    "    config(\"spark.ui.showConsoleProgress\", \"false\").\\\n",
    "    appName(\"MLlib\").\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# sc.setLogLevel(\"ERROR\")\n",
    "print(spark)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c810d39",
   "metadata": {},
   "source": [
    "### 数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ba0c2",
   "metadata": {},
   "source": [
    "我们依然使用弹幕数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cids = [144541892, 144541943, 160377038, 148952771, 150894103, 153392221, 156629080, 159982308, 162395026]\n",
    "cids = [144541892, 144541943, 160377038, 148952771, 150894103]\n",
    "jsons = [f\"data/lec14-danmu-{cid}.json\" for cid in cids]\n",
    "jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(jsons, multiLine=True)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113404ef",
   "metadata": {},
   "source": [
    "出于演示目的，我们随机抽取一小部分数据并缓存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.sample(withReplacement=False, fraction=0.001, seed=123)\n",
    "df_small.cache()\n",
    "df_small.show(n=15)\n",
    "df_small.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe487d9",
   "metadata": {},
   "source": [
    "### 数据转换与特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336c04f",
   "metadata": {},
   "source": [
    "除了 PySpark 自带的变换操作，我们还可以直接编写 Python 函数（基于 Pandas）对数据进行变换，如对弹幕进行分词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e6a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def seg_words(danmu):\n",
    "    # 弹幕通常包含大量空格以醒目，但破坏语义，先移除\n",
    "    danmu = danmu.replace(\" \", \"\")\n",
    "    # 生成一个含有切分后词语的迭代器\n",
    "    cut = jieba.lcut(danmu, cut_all=False)\n",
    "    # 去掉多余的空格\n",
    "    cut = filter(lambda x: x != \" \", cut)\n",
    "    # 再用空格将词语合并\n",
    "    return \" \".join(cut)\n",
    "\n",
    "seg_words_udf = udf(seg_words, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6f51d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_seg = df_small.withColumn(\"seg\", seg_words_udf(df_small.content))\n",
    "df_seg.cache()\n",
    "df_seg.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb339718",
   "metadata": {},
   "source": [
    "接下来使用 MLlib 中的 `Tokenizer` 转换器来将词语转为列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87a705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "\n",
    "tok = Tokenizer(inputCol=\"seg\", outputCol=\"words\")\n",
    "df_tok = tok.transform(df_seg)\n",
    "df_tok.select(\"seg\", \"words\").show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d059d82",
   "metadata": {},
   "source": [
    "移除停用词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"的\", \"了\", \"是\", \"，\", \"。\", \"？\", \"！\", \"：\", \"（\", \"）\", \"“\", \"”\", \".\", \"…\", \".\"]\n",
    "rmstop = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stop_words)\n",
    "df_rmstop = rmstop.transform(df_tok)\n",
    "df_rmstop.select(\"words\", \"filtered\").show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b1ab9",
   "metadata": {},
   "source": [
    "进而使用 `CountVectorizer` 来统计词频："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5d640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "# minDF 表示进入字典的词最少需要在多少句子（弹幕）中出现\n",
    "# vocabSize 表示取词频前几位的词语作为字典\n",
    "counter = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\",\n",
    "                          minDF=10, vocabSize=500)\n",
    "\n",
    "counter_model = counter.fit(df_rmstop)\n",
    "print(counter_model.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc84c8",
   "metadata": {},
   "source": [
    "将词频统计器应用到 `DataFrame` 上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafde1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_freq = counter_model.transform(df_rmstop)\n",
    "df_freq.select(\"filtered\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402e14f",
   "metadata": {},
   "source": [
    "再用 `IDF` 对词频进行规约化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa67ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "idf_model = idf.fit(df_freq)\n",
    "df_scaled = idf_model.transform(df_freq)\n",
    "df_scaled.select(\"content\", \"scaled_features\").show(n=15, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7924b2",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64324dea",
   "metadata": {},
   "source": [
    "我们利用得到的特征对弹幕进行 K-means 聚类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans().setK(10).setSeed(123)\n",
    "kmeans.setMaxIter(100)\n",
    "kmeans.setFeaturesCol(\"scaled_features\")\n",
    "\n",
    "kmeans_model = kmeans.fit(df_scaled)\n",
    "kmeans_model.setPredictionCol(\"cluster_labels\")\n",
    "\n",
    "df_pred = kmeans_model.transform(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783bc18",
   "metadata": {},
   "source": [
    "此时 `df_pred` 中包含了最终的聚类结果和若干中间变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09dd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f623b72",
   "metadata": {},
   "source": [
    "查看聚类结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15e6c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred.select(\"content\", \"cluster_labels\").groupBy(\"cluster_labels\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78eeb52",
   "metadata": {},
   "source": [
    "最后将聚类结果与原始弹幕和剧集相对照："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = spark.read.json(\"data/lec14-video-data.json\", multiLine=True)\n",
    "video_title = video_info.select(\"cid\", \"title\")\n",
    "video_title.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_pred.select(\"cid\", \"content\", \"cluster_labels\").filter(\"cluster_labels > 0\")\n",
    "df_res.join(video_title, df_res.cid == video_title.cid, \"inner\").drop(df_res.cid).\\\n",
    "    drop(video_title.cid).sort(\"cluster_labels\").show(n=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
