{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c204fbb",
   "metadata": {},
   "source": [
    "# 混洗（Shuffling）机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d9bba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x00000201EA0571C0>\n",
      "<SparkContext master=local[*] appName=Shuffling>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# 本地模式\n",
    "spark = SparkSession.builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    appName(\"Shuffling\").\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# sc.setLogLevel(\"ERROR\")\n",
    "print(spark)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d23f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5096\\1925336385.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(1000.0) # 报错\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(1000.0) # 报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203f6904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -2,  3,  4,  5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([-2, -1, 3, 4, 5])\n",
    "print(x > 0)\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([-1, -2, -3, -4, -5])\n",
    "np.where(x > 0, a, b) #R语言中ifelse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080a4e3",
   "metadata": {},
   "source": [
    "创建一个简单的 RDD："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d583d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "rdd = sc.parallelize(string.ascii_uppercase, numSlices=5) # 这里定义分成5份\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86fd6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fcd5d2",
   "metadata": {},
   "source": [
    "将每个分区的字母合并成一个字符串，从而可以知道分区是如何划分的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61ca93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCDE', 'FGHIJ', 'KLMNO', 'PQRST', 'UVWXYZ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_letters(iter):\n",
    "    yield \"\".join(iter)\n",
    "\n",
    "rdd.mapPartitions(concat_letters).collect() # 基本上按照等量原则"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56131e",
   "metadata": {},
   "source": [
    "将 RDD 重新分区，可以看出来字母的顺序产生了变化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1175ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'K', 'L', 'M', 'N', 'O', 'F', 'G', 'H', 'I', 'J']\n"
     ]
    }
   ],
   "source": [
    "rdd2 = rdd.repartition(6)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a47242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'ABCDE', 'PQRSTUVWXYZ', '', 'KLMNO', 'FGHIJ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.mapPartitions(concat_letters).collect() # 数据比较小的时候，随机进行划分\n",
    "# 注意算法是否依赖数据顺序"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a32bdb",
   "metadata": {},
   "source": [
    "使用 `toDebugString()` 查看 RDD 包含的操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d26d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5) ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274 []\n",
      "\n",
      "\n",
      "\n",
      "(6) MapPartitionsRDD[6] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[5] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[4] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(5) MapPartitionsRDD[3] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[2] at RDD at PythonRDD.scala:53 []\n",
      "    |  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274 []\n"
     ]
    }
   ],
   "source": [
    "print(rdd.toDebugString().decode(\"UTF-8\"))\n",
    "print(\"\\n\\n\")\n",
    "print(rdd2.toDebugString().decode(\"UTF-8\"))\n",
    "# 增加分区数很容易进行混洗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55351a4",
   "metadata": {},
   "source": [
    "可以看出来 `rdd2` 包含了混洗（shuffling）操作，这也是数据顺序打乱的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959af75",
   "metadata": {},
   "source": [
    "如果需要减小分区数目，可以使用 `coalesce()` 函数，避免混洗操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d68730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ABCDEFGHIJ', 'KLMNOPQRSTUVWXYZ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3 = rdd.coalesce(numPartitions=2, shuffle=False)\n",
    "print(rdd3.collect())\n",
    "rdd3.mapPartitions(concat_letters).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ba11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) CoalescedRDD[8] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274 []\n"
     ]
    }
   ],
   "source": [
    "print(rdd3.toDebugString().decode(\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba7aa82",
   "metadata": {},
   "source": [
    "如果确实需要增加分区数目，同时希望保持数据顺序，可以在原始 RDD 中增加索引信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ef8282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 0), ('B', 1), ('C', 2), ('D', 3), ('E', 4), ('F', 5), ('G', 6), ('H', 7), ('I', 8), ('J', 9), ('K', 10), ('L', 11), ('M', 12), ('N', 13), ('O', 14), ('P', 15), ('Q', 16), ('R', 17), ('S', 18), ('T', 19), ('U', 20), ('V', 21), ('W', 22), ('X', 23), ('Y', 24), ('Z', 25)]\n"
     ]
    }
   ],
   "source": [
    "print(rdd.zipWithIndex().collect()) # 如果想略过多少行，可以使用filter进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9829982d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 0), ('B', 1), ('C', 2), ('D', 3), ('E', 4), ('K', 10), ('L', 11), ('M', 12), ('N', 13), ('O', 14), ('P', 15), ('Q', 16), ('R', 17), ('S', 18), ('T', 19), ('F', 5), ('G', 6), ('H', 7), ('I', 8), ('J', 9), ('U', 20), ('V', 21), ('W', 22), ('X', 23), ('Y', 24), ('Z', 25)]\n"
     ]
    }
   ],
   "source": [
    "rdd4 = rdd.zipWithIndex().repartition(5)\n",
    "print(rdd4.collect()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5264d",
   "metadata": {},
   "source": [
    "然后定义一个分区映射函数，在合并数据行时获取分区中第一条数据的索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4483ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), ('ABCDE', 0), ('KLMNOPQRST', 10), ('FGHIJ', 5), ('UVWXYZ', 20)]\n"
     ]
    }
   ],
   "source": [
    "def concat_letters_with_order(iter): # 操作很复杂，对Index进行排序，保留第一个数据的索引\n",
    "    letters_and_indices = list(iter)\n",
    "    letters = map(lambda x: x[0], letters_and_indices)\n",
    "    indices = map(lambda x: x[1], letters_and_indices)\n",
    "    if len(letters_and_indices) < 1:\n",
    "        yield ()\n",
    "    else:\n",
    "        first_ind = next(indices)\n",
    "        combined_letters = \"\".join(letters)\n",
    "        yield combined_letters, first_ind\n",
    "\n",
    "rdd5 = rdd4.mapPartitions(concat_letters_with_order)\n",
    "print(rdd5.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709bf84",
   "metadata": {},
   "source": [
    "然后过滤空分区，并按生成的索引对 RDD 进行排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dfe9ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ABCDE', 0), ('KLMNOPQRST', 10), ('FGHIJ', 5), ('UVWXYZ', 20)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.filter(lambda x: len(x) > 1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b98d3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ABCDE', 0), ('FGHIJ', 5), ('KLMNOPQRST', 10), ('UVWXYZ', 20)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.filter(lambda x: len(x) > 1).sortBy(lambda x: x[1], ascending=True).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
